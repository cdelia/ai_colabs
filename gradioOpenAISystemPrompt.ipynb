{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3c+C00IMnlsGfKWQwP+jr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdelia/ai_colabs/blob/main/gradioOpenAISystemPrompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple gradio ChatBot Using OpenAI.\n",
        "It features streaming responses.\n"
      ],
      "metadata": {
        "id": "M0ZKGY452bxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install the requirements."
      ],
      "metadata": {
        "id": "x5KHMxij24WL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --q gradio openai"
      ],
      "metadata": {
        "id": "IHrUcJQXp4FZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's enter an OpenAI key.\n",
        "You can create one here: [page](https://platform.openai.com/account/api-keys)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UPmbU45R3B0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass as getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass.getpass(\"Enter OpenAI API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13v2h4O3r_j1",
        "outputId": "08589dd9-8626-48a6-ca53-ccada3cb7d9b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def predict(message, history, model, system_prompt, temperature):\n",
        "    history_openai_format = []\n",
        "    history_openai_format.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "    for human, assistant in history:\n",
        "        history_openai_format.append({\"role\": \"user\", \"content\": human })\n",
        "        history_openai_format.append({\"role\": \"assistant\", \"content\":assistant})\n",
        "    history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages= history_openai_format,\n",
        "        temperature=temperature,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    partial_message = \"\"\n",
        "    for chunk in response:\n",
        "        if len(chunk['choices'][0]['delta']) != 0:\n",
        "            partial_message = partial_message + chunk['choices'][0]['delta']['content']\n",
        "            yield partial_message\n",
        "\n",
        "demo = gr.ChatInterface(predict,\n",
        "                        additional_inputs=[\n",
        "                            gr.Radio([\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-4\", \"gpt-4-32k\"], value=\"gpt-3.5-turbo\", label=\"Model\"),\n",
        "                            gr.Textbox(\"You are helpful AI.\", label=\"System Prompt\"),\n",
        "                            gr.Slider(0.0, 1.0, label=\"Temperature\", step=0.01, value=0.9)\n",
        "                        ]\n",
        "                       )\n",
        "\n",
        "demo.queue().launch(debug=True)\n"
      ],
      "metadata": {
        "id": "Xu2WGx22q5S-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}